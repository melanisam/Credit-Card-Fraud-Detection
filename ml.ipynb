{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_pickle('fraud_data_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe54e6",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726aac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = df.copy()\n",
    "lr_df = lr_df[['category', 'trans_day', 'trans_month', 'trans_year', 'amt_zscore', 'amt_deviation', 'rolling_mean_amt', 'daily_txn_count', 'amt', 'hourly_txn_count', 'trans_dayofweek', 'trans_hour',\n",
    "               'is_fraud', 'city_pop', 'gender', 'dob_yr', 'cc_transaction_count', 'num_credit_cards']]          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = pd.get_dummies(lr_df, columns=['category', 'gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bef0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XLR = lr_df.drop(columns=['is_fraud'])\n",
    "yLR = lr_df['is_fraud']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XLR, yLR, test_size=0.2, random_state=42, stratify=yLR)\n",
    "\n",
    "# scale features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=XLR.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=XLR.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE MODEL\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# performance\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44295694",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'Feature': X_train.columns, 'Coefficient': np.abs(log_reg.coef_[0])}).reset_index()\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5de15",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = df.copy()\n",
    "\n",
    "rf_df = rf_df.drop(columns=['trans_date_trans_time', 'cc_num','state', 'trans_num', 'first_last'])\n",
    "\n",
    "rf_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply label encoding to categorical columns\n",
    "categorical_cols = ['merchant', 'category', 'gender', 'city', 'job']\n",
    "for col in categorical_cols:\n",
    "    rf_df[col] = LabelEncoder().fit_transform(rf_df[col])  \n",
    "\n",
    "# fit model\n",
    "XRF = rf_df.drop(columns=['is_fraud'])  \n",
    "yRF = rf_df['is_fraud']  \n",
    "X_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(XRF, yRF, test_size=0.2, random_state=42, stratify=yRF)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') \n",
    "rf_model.fit(X_train_RF, y_train_RF)\n",
    "y_pred_RF = rf_model.predict(X_test_RF)\n",
    "\n",
    "# performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test_RF, y_pred_RF))\n",
    "print(classification_report(y_test_RF, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train_RF.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Feature Importance for Random Forest model')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n",
    "\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating another random forest model with most important features \n",
    "rf_df_2 = df.copy()\n",
    "rf_df_2 = rf_df_2[['rolling_mean_amt', 'amt', 'amt_deviation', 'amt_zscore', 'trans_hour', 'category','is_fraud']]\n",
    "\n",
    "# encode category column\n",
    "rf_df_2['category'] = LabelEncoder().fit_transform(rf_df_2['category'])  \n",
    "\n",
    "\n",
    "X_RF2 = rf_df_2.drop(columns=['is_fraud'])\n",
    "y_RF2 = rf_df_2['is_fraud']\n",
    "X_train_RF2, X_test_RF2, y_train_RF2, y_test_RF2 = train_test_split(X_RF2, y_RF2, test_size=0.2, random_state=42, stratify=y_RF2)\n",
    "\n",
    "rf_model_2 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model_2.fit(X_train_RF2, y_train_RF2)\n",
    "\n",
    "\n",
    "y_pred_RF2 = rf_model_2.predict(X_test_RF2)\n",
    "\n",
    "# performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test_RF2, y_pred_RF2))\n",
    "print(classification_report(y_test_RF2, y_pred_RF2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance\n",
    "feature_importance = rf_model_2.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train_RF2.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# graph importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Feature Importance for 2nd Random Forest model')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()\n",
    "\n",
    "# print the feature importance\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now apply cross validation to this model \n",
    "# use stratified cross validation due to imbalanced classes\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_reports = []\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_RF2, y_RF2), 1):\n",
    "    print(f\"\\nTraining Fold {fold}...\\n\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X_RF2.iloc[train_idx], X_RF2.iloc[test_idx]\n",
    "    y_train, y_test = y_RF2.iloc[train_idx], y_RF2.iloc[test_idx]\n",
    "\n",
    "    # Train \n",
    "    rf_model_cv = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    rf_model_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict \n",
    "    y_pred = rf_model_cv.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    fold_accuracies.append(acc)\n",
    "    fold_reports.append(report)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Final mean\n",
    "print(f\"\\nAverage Accuracy Across Folds: {np.mean(fold_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f60e83",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc71183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0564914",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_df = df.copy()\n",
    "catboost_df=catboost_df.drop(columns=['cc_num', 'trans_num', 'state', 'first_last'])\n",
    "catboost_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['merchant', 'category', 'gender', 'city', 'job']\n",
    "X_C = catboost_df.drop(columns=['is_fraud'])\n",
    "y_C = catboost_df['is_fraud']\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X_C, y_C, test_size=0.2)\n",
    "\n",
    "# Train \n",
    "cat_model = CatBoostClassifier(n_estimators=100, cat_features=cat_features, verbose=0)\n",
    "cat_model.fit(X_train_C, y_train_C)\n",
    "\n",
    "y_pred_C = cat_model.predict(X_test_C)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test_C, y_pred_C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e37a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance\n",
    "feature_importance = cat_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train_C.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# graph importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Feature Importance for CatBoost model')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()\n",
    "\n",
    "# print the feature importance\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_df_2 = df.copy()\n",
    "catboost_df_2 = catboost_df_2[['amt','category','trans_hour','dob_yr','daily_txn_count','amt_zscore','rolling_mean_amt','hourly_txn_count','city_pop','city','is_fraud','amt_deviation', 'cc_transaction_count']]\n",
    "cat_features = ['category', 'city']\n",
    "X_C2 = catboost_df_2.drop(columns=['is_fraud'])\n",
    "y_C2 = catboost_df_2['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81607e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply cross validation to this model \n",
    "\n",
    "\n",
    "# use stratified cross validation due to imbalanced classes\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_reports = []\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_C2, y_C2), 1):\n",
    "    print(f\"\\nTraining Fold {fold}...\\n\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X_C2.iloc[train_idx], X_C2.iloc[test_idx]\n",
    "    y_train, y_test = y_C2.iloc[train_idx], y_C2.iloc[test_idx]\n",
    "\n",
    "    # Train \n",
    "    cat_model_cv = CatBoostClassifier(n_estimators=200, cat_features=cat_features, verbose=0)\n",
    "    cat_model_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict \n",
    "    y_pred = cat_model_cv.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    fold_accuracies.append(acc)\n",
    "    fold_reports.append(report)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Final mean\n",
    "print(f\"\\nAverage Accuracy Across Folds: {np.mean(fold_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Importance\n",
    "feature_importance = cat_model_cv.get_feature_importance()\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_C2.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Feature Importance - CatBoost')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Fraud\", \"Fraud\"], yticklabels=[\"Not Fraud\", \"Fraud\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0757e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get probabilities\n",
    "y_probs = cat_model_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# plot\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9161dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get roc auc score\n",
    "y_pred_probs = cat_model_cv.predict_proba(X_test)[:, 1]  \n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)  \n",
    "\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot roc curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.5f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier (AUC = 0.5)')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
